{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtAOWzygHC+5YZLnvQYoci",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditijoshi613/Attention-Is-All-You-Need/blob/main/Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5Q5MQb6Bg_6"
      },
      "outputs": [],
      "source": [
        "dutch = 'Dies führt dazu, dass ein Spieler wie ich, die Stirn bieten muss und sein Bestes geben will.'\n",
        "english = 'Which is what makes a player like me want to face up and give my best.'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# implement a BytePairEncoding Tokenizer"
      ],
      "metadata": {
        "id": "acCQy_6biX_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use a normal tokenizer for now\n",
        "input = english.split(' ')\n",
        "output = dutch.split(' ')"
      ],
      "metadata": {
        "id": "kyzgblTSjCYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download required dataset\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTMQpUXWyHbc",
        "outputId": "45cecff3-0013-4a02-ec41-9cf8a7342ef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_input = word_tokenize(english)\n",
        "tokenized_output = word_tokenize(dutch)\n",
        "tokenized_input, tokenized_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRiX5M7myw0S",
        "outputId": "e4a4cce1-eaff-426b-e328-e80d1a90ab78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Which',\n",
              "  'is',\n",
              "  'what',\n",
              "  'makes',\n",
              "  'a',\n",
              "  'player',\n",
              "  'like',\n",
              "  'me',\n",
              "  'want',\n",
              "  'to',\n",
              "  'face',\n",
              "  'up',\n",
              "  'and',\n",
              "  'give',\n",
              "  'my',\n",
              "  'best',\n",
              "  '.'],\n",
              " ['Dies',\n",
              "  'führt',\n",
              "  'dazu',\n",
              "  ',',\n",
              "  'dass',\n",
              "  'ein',\n",
              "  'Spieler',\n",
              "  'wie',\n",
              "  'ich',\n",
              "  ',',\n",
              "  'die',\n",
              "  'Stirn',\n",
              "  'bieten',\n",
              "  'muss',\n",
              "  'und',\n",
              "  'sein',\n",
              "  'Bestes',\n",
              "  'geben',\n",
              "  'will',\n",
              "  '.'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8CH_XD70CDW",
        "outputId": "cb03a08e-ea41-4ad6-91dd-cc61d0bc78df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Collecting torch\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nvjitlink-cu12-12.4.127 torch-2.6.0 triton-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "9NkLY_pojfIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "k6QF7wRdjMM_",
        "outputId": "3f8bb37e-24e8-46e7-fef9-035fe5f3ffe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.randn(10, requires_grad=True)\n",
        "output_tensor = torch.randn(10, requires_grad=True)"
      ],
      "metadata": {
        "id": "jNb-2rRI1zew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor"
      ],
      "metadata": {
        "id": "rNVGH8inZ1s0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5e23106-bdc3-4f97-9274-79461fb12570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.4752,  0.4416,  1.4806, -1.9011, -0.3604, -0.6952,  0.1120, -0.3365,\n",
              "        -1.0820,  1.6302], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQd5fInbze8-",
        "outputId": "a27f1a9a-da64-412f-c75e-74209900917c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def multihead_attention(query, key, value, embedding_dim, linear_1, linear_2, mask=False, num_heads=8):\n",
        "  heads = torch.zeros(value.size(dim=0), embedding_dim/num_heads)\n",
        "  softmax = nn.Softmax(dim=1)\n",
        "  # linear transformation\n",
        "  query = linear_1(query)\n",
        "  key = linear_1(key)\n",
        "  value = linear_1(value)\n",
        "  mat = torch.matmul(query, torch.transpose(key)/torch.sqrt(embedding_dim))\n",
        "  # masked multi-head attention\n",
        "  if mask:\n",
        "    mask = torch.tril(torch.ones_like(mat), diagonal=0).bool()\n",
        "    mat = mat.masked_fill(mask, float('-inf'))\n",
        "  heads = softmax(mat)\n",
        "  heads = torch.matmul(heads, value)\n",
        "  attention = linear_2(torch.concatenate(heads, dim=1))\n",
        "  return attention"
      ],
      "metadata": {
        "id": "X5CIOx1f68Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_dim, num_heads=8, embedding_dim=512, feed_forward_dim=2048) -> None:\n",
        "    super(Encoder, self).__init__()\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.num_heads = num_heads\n",
        "    self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "    self.positional_encoding = torch.zeros(input_dim, embedding_dim)\n",
        "    numerator = torch.arange(0, input_dim).unsqueeze(1)\n",
        "    denominator = torch.arange(0, embedding_dim, 2)/embedding_dim\n",
        "    denominator = torch.pow(10000, denominator)\n",
        "    self.positional_encoding[:, 0::2] = torch.sin(numerator/denominator)\n",
        "    self.positional_encoding[:, 1::2] = torch.cos(numerator/denominator)\n",
        "    self.layer_norm = torch.nn.LayerNorm(self.embedding_dim)\n",
        "    self.feed_forward_1 = nn.Linear(in_features=self.embedding_dim, out_features=feed_forward_dim)\n",
        "    self.feed_forward_2 = nn.Linear(in_features=feed_forward_dim, out_features=embedding_dim)\n",
        "    self.activation = nn.ReLU()\n",
        "    # linear transformations for multi-head attention\n",
        "    self.linear_1 = nn.Linear(embedding_dim, int(embedding_dim/self.num_heads))\n",
        "    self.linear_1.bias.data.fill_(0)\n",
        "    self.linear_2 = nn.Linear(in_features=embedding_dim, out_features=embedding_dim)\n",
        "    self.linear_2.bias.data.fill_(0)\n",
        "\n",
        "  def forward(self, input):\n",
        "    # sub-layer 1\n",
        "    # generate embedding for the input\n",
        "    embedded = self.embedding(input)\n",
        "    # concatenate with positional encoding\n",
        "    embedded = embedded + self.positional_encoding\n",
        "    # implement multihead attention\n",
        "    attention_output = multihead_attention(embedded, embedded, embedded, self.embedding_dim, self.linear_1, self.linear_2, mask=False, num_heads=self.num_heads)\n",
        "    # residual connection\n",
        "    attention_output = attention_output + embedded\n",
        "    # layer normalization\n",
        "    normalized = self.layer_norm(attention_output)\n",
        "    # sub-layer 2\n",
        "    # point-wise feed forward network\n",
        "    ff = self.feed_forward_1(normalized)\n",
        "    ff = self.feed_forward_2(self.activation(ff))\n",
        "    # residual connection\n",
        "    ff_res = ff + normalized\n",
        "    # layer normalization\n",
        "    ff_normalized = self.layer_norm(ff_res)\n",
        "\n",
        "    return ff_normalized"
      ],
      "metadata": {
        "id": "Tfwhs1R3jhgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_dim -- input vocab size\n",
        "# output_dim -- output vocab size"
      ],
      "metadata": {
        "id": "n7lR0EqaGayI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Encoder(10).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "Vs0swCrg2N1x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4f83286-aba8-4441-dc46-767745413abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder(\n",
            "  (embedding): Embedding(10, 512)\n",
            "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (feed_forward_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "  (feed_forward_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "  (activation): ReLU()\n",
            "  (linear_1): Linear(in_features=512, out_features=64, bias=True)\n",
            "  (linear_2): Linear(in_features=512, out_features=512, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(list(model.parameters()))  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "og6GRGxUL8p4",
        "outputId": "09a28bf3-163b-431c-fd19-60f66c34f5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name}, Shape: {param.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzkAt0bjQQsh",
        "outputId": "5f1b3e1f-acb4-4672-be25-03d25328be58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: embedding.weight, Shape: torch.Size([10, 512])\n",
            "Layer: layer_norm.weight, Shape: torch.Size([512])\n",
            "Layer: layer_norm.bias, Shape: torch.Size([512])\n",
            "Layer: feed_forward_1.weight, Shape: torch.Size([2048, 512])\n",
            "Layer: feed_forward_1.bias, Shape: torch.Size([2048])\n",
            "Layer: feed_forward_2.weight, Shape: torch.Size([512, 2048])\n",
            "Layer: feed_forward_2.bias, Shape: torch.Size([512])\n",
            "Layer: linear_1.weight, Shape: torch.Size([64, 512])\n",
            "Layer: linear_1.bias, Shape: torch.Size([64])\n",
            "Layer: linear_2.weight, Shape: torch.Size([512, 512])\n",
            "Layer: linear_2.bias, Shape: torch.Size([512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, output_dim, num_heads=8, embedding_dim=512, feed_forward_dim=2048) -> None:\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.num_heads = num_heads\n",
        "    self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
        "    self.positional_encoding = torch.zeros(output_dim, embedding_dim)\n",
        "    numerator = torch.arange(0, output_dim).unsqueeze(1)\n",
        "    denominator = torch.arange(0, embedding_dim, 2)/embedding_dim\n",
        "    denominator = torch.pow(10000, denominator)\n",
        "    self.positional_encoding[:, 0::2] = torch.sin(numerator/denominator)\n",
        "    self.positional_encoding[:, 1::2] = torch.cos(numerator/denominator)\n",
        "    self.layer_norm = torch.nn.LayerNorm(self.embedding_dim)\n",
        "    self.feed_forward_1 = nn.Linear(in_features=self.embedding_dim, out_features=feed_forward_dim)\n",
        "    self.feed_forward_2 = nn.Linear(in_features=feed_forward_dim, out_features=embedding_dim)\n",
        "    self.activation = nn.ReLU()\n",
        "    self.linear = nn.Linear(self.embedding_dim, output_dim)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    # linear transformations for multi-head attention\n",
        "    self.linear_1 = nn.Linear(embedding_dim, int(embedding_dim/self.num_heads))\n",
        "    self.linear_1.bias.data.fill_(0)\n",
        "    self.linear_2 = nn.Linear(in_features=embedding_dim, out_features=embedding_dim)\n",
        "    self.linear_2.bias.data.fill_(0)\n",
        "    self.linear_3 = nn.Linear(embedding_dim, int(embedding_dim/self.num_heads))\n",
        "    self.linear_3.bias.data.fill_(0)\n",
        "    self.linear_4 = nn.Linear(in_features=embedding_dim, out_features=embedding_dim)\n",
        "    self.linear_4.bias.data.fill_(0)\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, output, encoder_output):\n",
        "    # sub-layer 1\n",
        "    # generate embedding for the output\n",
        "    embedded = self.embedding(output)\n",
        "    # concatenate with positional encoding\n",
        "    embedded = embedded + self.positional_encoding\n",
        "    # implement multihead attention\n",
        "    attention_output = multihead_attention(embedded, embedded, embedded, self.embedding_dim, self.linear_1, self.linear_2, mask=True, num_heads=self.num_heads)\n",
        "    # residual connection\n",
        "    attention_output = attention_output + embedded\n",
        "    # layer normalization\n",
        "    normalized = self.layer_norm(attention_output)\n",
        "    # sub-layer 2\n",
        "    # cross-attention\n",
        "    cross_attention_output = multihead_attention(normalized, encoder_output, encoder_output, self.embedding_dim, self.linear_3, self.linear_4, mask=True, num_heads=self.num_heads)\n",
        "    # residual connection\n",
        "    cross_attention_output = cross_attention_output + normalized\n",
        "    # layer normalization\n",
        "    normalized_2 = self.layer_norm(cross_attention_output)\n",
        "    # sublayer 3\n",
        "    # point-wise feed forward network\n",
        "    ff = self.feed_forward_1(normalized_2)\n",
        "    ff = self.feed_forward_2(self.activation(ff))\n",
        "    # residual connection\n",
        "    ff_res = ff + normalized\n",
        "    # layer normalization\n",
        "    ff_normalized = self.layer_norm(ff_res)\n",
        "    # linear layer\n",
        "    output = self.linear(ff_normalized)\n",
        "    # softmax layer\n",
        "    output = self.softmax(output)\n",
        "    return output\n",
        "\n",
        "\n",
        "    return ff_normalized"
      ],
      "metadata": {
        "id": "hKpykpiV4ytd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Decoder(10).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQycNEuZH78U",
        "outputId": "cb9f5ba6-a546-440f-dfa6-5ee0187ddfe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder(\n",
            "  (embedding): Embedding(10, 512)\n",
            "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (feed_forward_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "  (feed_forward_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "  (activation): ReLU()\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            "  (softmax): Softmax(dim=1)\n",
            "  (linear_1): Linear(in_features=512, out_features=64, bias=True)\n",
            "  (linear_2): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (linear_3): Linear(in_features=512, out_features=64, bias=True)\n",
            "  (linear_4): Linear(in_features=512, out_features=512, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name}, Shape: {param.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-72JudIZQ1Qk",
        "outputId": "8df54c76-7987-46dd-c4db-fa3db671eb29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: embedding.weight, Shape: torch.Size([10, 512])\n",
            "Layer: layer_norm.weight, Shape: torch.Size([512])\n",
            "Layer: layer_norm.bias, Shape: torch.Size([512])\n",
            "Layer: feed_forward_1.weight, Shape: torch.Size([2048, 512])\n",
            "Layer: feed_forward_1.bias, Shape: torch.Size([2048])\n",
            "Layer: feed_forward_2.weight, Shape: torch.Size([512, 2048])\n",
            "Layer: feed_forward_2.bias, Shape: torch.Size([512])\n",
            "Layer: linear.weight, Shape: torch.Size([10, 512])\n",
            "Layer: linear.bias, Shape: torch.Size([10])\n",
            "Layer: linear_1.weight, Shape: torch.Size([64, 512])\n",
            "Layer: linear_1.bias, Shape: torch.Size([64])\n",
            "Layer: linear_2.weight, Shape: torch.Size([512, 512])\n",
            "Layer: linear_2.bias, Shape: torch.Size([512])\n",
            "Layer: linear_3.weight, Shape: torch.Size([64, 512])\n",
            "Layer: linear_3.bias, Shape: torch.Size([64])\n",
            "Layer: linear_4.weight, Shape: torch.Size([512, 512])\n",
            "Layer: linear_4.bias, Shape: torch.Size([512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ManualTransformer(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim, num_heads=8, embedding_dim=512,feed_forward_dim=2048) -> None:\n",
        "    super(ManualTransformer, self).__init__()\n",
        "    self.encoder = Encoder(input_dim, num_heads=num_heads, embedding_dim=embedding_dim,feed_forward_dim=feed_forward_dim)\n",
        "    self.decoder = Decoder(output_dim=output_dim, num_heads=num_heads, embedding_dim=512, feed_forward_dim=2048)\n",
        "\n",
        "  def forward(self, input, output):\n",
        "    encoder_output = self.encoder(input)\n",
        "    decoder_output = self.decoder(output, encoder_output)\n",
        "    return decoder_output\n",
        "\n"
      ],
      "metadata": {
        "id": "rYKECCGbDVPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ManualTransformer(input_dim=10, output_dim=10, num_heads=8, embedding_dim=512,feed_forward_dim=2048).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4T2m4ySH3RX",
        "outputId": "5c014d6c-31cf-4da4-8cf5-196d350b3a30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ManualTransformer(\n",
            "  (encoder): Encoder(\n",
            "    (embedding): Embedding(10, 512)\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "    (feed_forward_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "    (feed_forward_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "    (activation): ReLU()\n",
            "    (linear_1): Linear(in_features=512, out_features=64, bias=True)\n",
            "    (linear_2): Linear(in_features=512, out_features=512, bias=True)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (embedding): Embedding(10, 512)\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "    (feed_forward_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "    (feed_forward_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "    (activation): ReLU()\n",
            "    (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (softmax): Softmax(dim=1)\n",
            "    (linear_1): Linear(in_features=512, out_features=64, bias=True)\n",
            "    (linear_2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (linear_3): Linear(in_features=512, out_features=64, bias=True)\n",
            "    (linear_4): Linear(in_features=512, out_features=512, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name}, Shape: {param.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3ZjziqgH41u",
        "outputId": "3951862e-a462-4e7a-b476-4f073767cebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: encoder.embedding.weight, Shape: torch.Size([10, 512])\n",
            "Layer: encoder.layer_norm.weight, Shape: torch.Size([512])\n",
            "Layer: encoder.layer_norm.bias, Shape: torch.Size([512])\n",
            "Layer: encoder.feed_forward_1.weight, Shape: torch.Size([2048, 512])\n",
            "Layer: encoder.feed_forward_1.bias, Shape: torch.Size([2048])\n",
            "Layer: encoder.feed_forward_2.weight, Shape: torch.Size([512, 2048])\n",
            "Layer: encoder.feed_forward_2.bias, Shape: torch.Size([512])\n",
            "Layer: encoder.linear_1.weight, Shape: torch.Size([64, 512])\n",
            "Layer: encoder.linear_1.bias, Shape: torch.Size([64])\n",
            "Layer: encoder.linear_2.weight, Shape: torch.Size([512, 512])\n",
            "Layer: encoder.linear_2.bias, Shape: torch.Size([512])\n",
            "Layer: decoder.embedding.weight, Shape: torch.Size([10, 512])\n",
            "Layer: decoder.layer_norm.weight, Shape: torch.Size([512])\n",
            "Layer: decoder.layer_norm.bias, Shape: torch.Size([512])\n",
            "Layer: decoder.feed_forward_1.weight, Shape: torch.Size([2048, 512])\n",
            "Layer: decoder.feed_forward_1.bias, Shape: torch.Size([2048])\n",
            "Layer: decoder.feed_forward_2.weight, Shape: torch.Size([512, 2048])\n",
            "Layer: decoder.feed_forward_2.bias, Shape: torch.Size([512])\n",
            "Layer: decoder.linear.weight, Shape: torch.Size([10, 512])\n",
            "Layer: decoder.linear.bias, Shape: torch.Size([10])\n",
            "Layer: decoder.linear_1.weight, Shape: torch.Size([64, 512])\n",
            "Layer: decoder.linear_1.bias, Shape: torch.Size([64])\n",
            "Layer: decoder.linear_2.weight, Shape: torch.Size([512, 512])\n",
            "Layer: decoder.linear_2.bias, Shape: torch.Size([512])\n",
            "Layer: decoder.linear_3.weight, Shape: torch.Size([64, 512])\n",
            "Layer: decoder.linear_3.bias, Shape: torch.Size([64])\n",
            "Layer: decoder.linear_4.weight, Shape: torch.Size([512, 512])\n",
            "Layer: decoder.linear_4.bias, Shape: torch.Size([512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# git version control\n",
        "# implement initialization\n",
        "# combine encoder and decoder - done\n",
        "# masking - cross-attention - done\n",
        "# implement 6 layers\n",
        "# implement parallelization\n",
        "# batch the input - for parallelization\n",
        "#  If implementing attention manually, use batch matrix multiplication (torch.bmm) or torch.einsum for efficient parallelization.\n",
        "# .to('cuda')\n",
        "# Matrix multiplications (torch.matmul) are executed in parallel.\n",
        "#Uses a single linear layer (qkv_proj) to compute Q, K, V in parallel.\n",
        "# Avoids looping over heads by using .reshape() and .unbind().\n",
        "# Uses torch.matmul() for parallel attention computation"
      ],
      "metadata": {
        "id": "fpRGAwUtq1v8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output is right shifted"
      ],
      "metadata": {
        "id": "zbo38l08Eyog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Many layers inside a neural network are parameterized, i.e. have associated\n",
        "# weights and biases that are optimized during training.\n",
        "# Subclassing nn.Module automatically tracks all fields defined inside your\n",
        "# model object, and makes all parameters accessible using your model’s\n",
        "# parameters() or named_parameters() methods."
      ],
      "metadata": {
        "id": "FZfyuXVXIxf9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}